# -*- coding: utf-8 -*-
"""CitizenAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iGlF6qOqtzChYNNrseqe1gE-7SFIWQuh
"""

# -*- coding: utf-8 -*-
"""CitizenAI Advanced Version"""

!pip install transformers torch gradio -q

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Load model
model_name = "ibm-granite/granite-3.2-2b-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# Core response generator
def generate_response(prompt, max_length=1024):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    if torch.cuda.is_available():
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id
        )
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    response = response.replace(prompt, "").strip()
    return response

# City Analysis with Custom Options
def city_analysis(city_name, aspects, detail_level, language):
    aspect_text = "\n".join([f"- {a}" for a in aspects])
    detail_prompt = "detailed" if detail_level == "Detailed Report" else "brief summary"

    prompt = (
        f"Provide a {detail_prompt} of the following aspects for the city of {city_name}:\n"
        f"{aspect_text}\n\nRespond in {language}.\n\nCity: {city_name}\nAnalysis:"
    )
    return generate_response(prompt, max_length=1024)

# Citizen Query with language and detail option
def citizen_interaction(query, detail_level, language):
    detail_prompt = "detailed" if detail_level == "Detailed Report" else "concise"
    prompt = (
        f"As a government assistant, provide a {detail_prompt} and helpful response in {language} "
        f"to the following citizen query:\n\nQuery: {query}\nResponse:"
    )
    return generate_response(prompt, max_length=1000)

# Download feature
def download_report(text):
    with open("CitizenAI_Report.txt", "w", encoding="utf-8") as f:
        f.write(text)
    return "CitizenAI_Report.txt"

# Interface
with gr.Blocks() as app:
    gr.Markdown("# üèôÔ∏è CitizenAI - Smart City & Civic Assistant")

    with gr.Tabs():
        with gr.TabItem("üìä City Analysis"):
            with gr.Row():
                with gr.Column():
                    city_input = gr.Textbox(label="City Name", placeholder="e.g., Tokyo")
                    aspects = gr.CheckboxGroup(
                        choices=[
                            "Crime Index",
                            "Accident Rates",
                            "Air Quality",
                            "Healthcare Access",
                            "Public Transport"
                        ],
                        label="Select Aspects to Analyze",
                        value=["Crime Index", "Accident Rates"]
                    )
                    detail_level_city = gr.Radio(["Brief Summary", "Detailed Report"], label="Report Detail")
                    language_city = gr.Dropdown(["English", "Spanish", "French"], value="English", label="Response Language")
                    analyze_btn = gr.Button("Analyze City")

                with gr.Column():
                    city_output = gr.Textbox(label="City Analysis Output", lines=20)
                    download_btn_city = gr.Button("Download Report")
                    file_output_city = gr.File()

            analyze_btn.click(city_analysis, inputs=[city_input, aspects, detail_level_city, language_city], outputs=city_output)
            download_btn_city.click(download_report, inputs=city_output, outputs=file_output_city)

        with gr.TabItem("üôã Citizen Services"):
            with gr.Row():
                with gr.Column():
                    citizen_query = gr.Textbox(label="Your Query", placeholder="Ask about taxes, healthcare, etc.", lines=4)
                    detail_level_citizen = gr.Radio(["Brief Summary", "Detailed Report"], label="Response Detail")
                    language_citizen = gr.Dropdown(["English", "Spanish", "French"], value="English", label="Response Language")
                    query_btn = gr.Button("Get Information")

                with gr.Column():
                    citizen_output = gr.Textbox(label="Government Response", lines=20)
                    download_btn_citizen = gr.Button("Download Response")
                    file_output_citizen = gr.File()

            query_btn.click(citizen_interaction, inputs=[citizen_query, detail_level_citizen, language_citizen], outputs=citizen_output)
            download_btn_citizen.click(download_report, inputs=citizen_output, outputs=file_output_citizen)

app.launch(share=True)